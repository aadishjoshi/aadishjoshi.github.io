---
layout: post
title: "NLP Pipeline"
categories: nlp
---

# NLP Pipeline Steps


<img src="/assets/images/nlp_pipeline.png" alt="nlp_primar" class="profile-pic" />


## 1. Data Acquisition
- **Use public datasets**
- **Scrape data**
- **Data augmentation**
    - Synonym replacement
    - Back Translation (Hindi → English → Hindi)
    - TF-IDF-based word replacement
    - Bigram flipping
    - Replacing entities
    - Adding noise to data *(fat finger problem - closest letter on QWERTY keyboard)*
    - Active Learning

---

## 2. Text Extraction & Cleanup
- **HTML Parsing**
    - BeautifulSoup
- **Unicode normalization**
- **Spelling correction**
- **OCR**
    - Tesseract

---

## 3. Pre-Processing
- **Preliminaries**
    - Sentence Segmentation
    - Word Tokenization
- **Frequent Steps**
    - Stop word removal
    - Stemming and Lemmatization
    - Removing digits / punctuations
    - Lowercasing
- **Other**
    - Normalization *(e.g., social media abbreviation → full form)*
    - Language Detection
    - Code mixing
    - Transliteration *(e.g., different language written using English text)*
- **Advanced Parsing**
    - POS Tagging
    - Parsing
    - Coreference Resolution

---

## 4. Feature Engineering
- Text representation for Deep Learning (DL)

---

## 5. Modeling
- Model stacking and Ensembling

---

## 6. Evaluation
- **Intrinsic Evaluation**
    - Output compared against correct labels




| Metric     | Description                                                                                                              | Use Cases                                            |
|:-----------|:-------------------------------------------------------------------------------------------------------------------------|:-----------------------------------------------------|
| Accuracy   | Total correct prediction / Total predictions                                                                             | Binary classification, multiclass sentiment analysis |
| Precision  | Correct prediction / Total correct predictions                                                                           | Disease predictions etc                              |
| Recall     | The model predicts positive, how many of them are indeed positive                                                        | E-commerce searches, info retrieval tasks            |
| F1 Score   | 2 * Precision * Recall / (P + R)                                                                                         | Sequence labeling; simultaneously used with accuracy |
| AUC        | Used to find optimal prediction threshold for classification task                                                        |                                                      |
| MRR        | Used to evaluate responses received given their prob of correctness mean reciprocal rank                                 | Info retrieval, e-commerce search                    |
| MAP        | Mean avg precision                                                                                                       | Info retrieval                                       |
| RMSE       | Continuous output variable                                                                                               |                                                      |
| MAPE       | Continuous output variable                                                                                               |                                                      |
| BLEU       | Bilingual Evaluation understudy. Captures n-gram overlaps. Recently adapted to text generation, paraphrase generation    |                                                      |
| METEOR     | Precision-based metric to measure the quality of text generated. Exact word matching. Allows synonyms, and stemmed words | Machine translation                                  |
| ROUGE      | Measures recall as opposed to BLEU                                                                                       | Text summarization                                   |
| Perplexity | How confused an NLP model is; derived from cross entropy in the next word prediction task.                               | Evaluate language models and language generation     |